# TowerDefenseRL
Reinforcement learning agent for my [Tower Defense Game](https://github.com/Jacky8703/TowerDefenseGame).

## Features

- Integration with the Tower Defense Game (custom Gymnasium environment)
- Training script using Stable Baselines3 (maskable PPO algorithm)
- Tensorboard for monitoring training progress (with custom metrics)
- Model saving and loading
- Video recording of agent gameplay
- Script for replaying the best agent game actions from training (max waves reached)
- Random map selection during training for better generalization

# TODO list
â€œäº‹å‰ç¦æ­¢â€
1. - [ ] è·‘é€šsb3-DQN ï¼Œbaseline DQN v.s. PPO å®˜æ–¹å®ç°
2. - [ ] handmade DQN
3. - [ ] DQN ä¼˜åŒ–ï¼ˆç¼©å° action space / double DQN / dueling DQNï¼Œ offline studyï¼‰
4. - [ ] agent åªè¦è¿”å›å°±è¿”å›æœ‰æ„ä¹‰çš„actionï¼Œå‡å°‘maskçš„ä½¿ç”¨ -- ç›®å‰çš„maskæ˜¯â€œäº‹åæƒ©ç½šâ€ï¼Œè€Œä¸æ˜¯â€œäº‹å‰ç¦æ­¢â€
5. - [ ] æ˜¯å¦å¯ä»¥å¼•å…¥äººç±»å…ˆéªŒï¼Ÿå¦‚ä½•è¡¨ç¤ºäººç±»ç­–ç•¥ï¼Ÿï¼ˆæ¨¡ä»¿å­¦ä¹  / ç¦»çº¿ RLï¼‰
6. - [ ] å¼•å…¥LLM ä½œä¸ºç­–ç•¥æŒ‡å¯¼/æ‰“åˆ†

## Installation
### æ³¨æ„
- å…ˆæ£€æµ‹CUDAç‰ˆæœ¬
- å®Œç¾ï¼Œæˆ‘æ¥ç›´æ¥ç»™ä½  **æœ€å®‰å…¨ã€æœ€å…¼å®¹ã€ä¸ä¼šå†æœ‰ NumPy / cv2 / SB3 / Gym ç­‰å†²çª** çš„å®‰è£…æ–¹æ¡ˆã€‚

ä½ çš„ `requirements.txt` **æ— æ³•ç›´æ¥ç”¨**ï¼Œå› ä¸ºå®ƒé‡Œé¢åŒ…å«å¤§é‡ **ä¸å…¼å®¹ NumPy 2.x æˆ–ä¸å…¼å®¹ Torch 2.8** çš„åº“ã€‚
å¦‚æœä½ æŒ‰å®ƒå®‰è£…ï¼Œä½ çš„æ–°ç¯å¢ƒé©¬ä¸Šå°±ä¼šåƒä¹‹å‰ä¸€æ ·ç‚¸æ‰ã€‚

---

### âœ… **ç»“è®ºï¼šPython 3.10 æ˜¯æœ€æ¨èçš„ï¼**

âœ” å®Œå…¨æ”¯æŒ Stable-Baselines3
âœ” å®Œå…¨æ”¯æŒ Gymnasium
âœ” å®Œå…¨æ”¯æŒ PyTorch
âœ” å„ç§ç§‘å­¦è®¡ç®—åº“ä¹Ÿå…¼å®¹æœ€ä½³

â†’ æ‰€ä»¥ä½ ç°åœ¨çš„ `(rl)` ç¯å¢ƒé€‰ Python 3.10 **éå¸¸æ­£ç¡®**ã€‚

---

### â— ä½ å¿…é¡»é‡æ–°æ•´ç† requirementsï¼ˆå°¤å…¶æ˜¯ numpy / fsspec / protobufï¼‰

 requirements åŒ…å«ï¼š

```
numpy==2.3.3
fsspec==2025.9.0
protobuf==6.32.1
torch==2.8.0
```

è¿™äº›ç‰ˆæœ¬ä¼šè®©ç»å¤§éƒ¨åˆ† RL åº“ç›´æ¥å´©æºƒã€‚

---

### ğŸš« **è¿™äº›ç‰ˆæœ¬ä¸èƒ½ç”¨ï¼ˆä¼šå´©ï¼‰**

| åŒ…å                  | ä½ çš„ç‰ˆæœ¬                            | é—®é¢˜                       |
| ------------------- | ------------------------------- | ------------------------ |
| **numpy 2.3.3**     | âŒ ä¸å…¼å®¹ opencvã€numbaã€gym çš„éƒ¨åˆ† C æ‰©å±• | ä½ çš„ä¹‹å‰æŠ¥é”™å°±æ˜¯å› ä¸ºè¿™ä¸ª             |
| **fsspec 2025.9.0** | âŒ æœªæ¥ç‰ˆæœ¬ï¼Œdatasets ä¸èƒ½ç”¨             | æ²¡æœ‰ç†ç”±è£…è¿™ä¹ˆæ–°çš„                |
| **protobuf 6.32.1** | âŒ wandbã€tensorboard ä¸å…¼å®¹         |                          |
| **torch 2.8.0**     | âŒ SB3 æœªéªŒè¯ï¼Œå¯èƒ½ä¼šå¯¼è‡´ CUDA / API ä¸å…¼å®¹  | SB3 å®˜æ–¹éªŒè¯åªåˆ° torch==2.3 å·¦å³ |

---

### ğŸŸ© æ­£ç¡®ã€å®‰å…¨çš„ RL ç¯å¢ƒéœ€æ±‚å¦‚ä¸‹ï¼š

### **æ ¸å¿ƒä¾èµ–ï¼ˆSB3 å®˜æ–¹æ¨èï¼‰**

| åŒ…                 | æ¨èç‰ˆæœ¬                    |
| ----------------- | ----------------------- |
| numpy             | **1.24.x** æˆ– 1.26.x     |
| torch             | **2.3.x**ï¼ˆæ­£å¼æ”¯æŒï¼‰ æˆ– 2.2.x |
| gymnasium         | 1.0+                    |
| stable-baselines3 | 2.3.2 æˆ– 2.7.0           |
| opencv-python     | æœ€æ–°ï¼ˆå…¼å®¹ numpy 1.xï¼‰        |

---

### ğŸ§© **æ‰€ä»¥ä½ åº”è¯¥è¿™æ ·å®‰è£…ï¼Œä¸è¦ç”¨åŸæœ¬çš„ requirements.txt**

æˆ‘ç»™ä½ ä¸€å¥—æœ€å…¼å®¹çš„ RL ç¯å¢ƒå®‰è£…å‘½ä»¤ï¼ˆé€‚ç”¨äº CPU æˆ– GPUï¼‰ã€‚

---

### âœ… **ç¬¬ä¸€æ­¥ï¼šæ¿€æ´»ç¯å¢ƒ**

```bash
conda activate rl
```

---

### âœ… **ç¬¬äºŒæ­¥ï¼šå®‰è£… PyTorch ï¼ˆæ¨èç‰ˆæœ¬ï¼Œä¸æ˜¯ 2.8ï¼‰**

### â­ å¦‚æœä½ ç”¨ CPUï¼š

```bash
pip install torch==2.3.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
```

### â­ å¦‚æœä½ ç”¨ NVIDIA GPUï¼ˆCUDA 12.1ï¼‰ï¼š

```bash
pip install torch==2.3.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

> Torch 2.8 å¯¹ SB3 æ¥è¯´å¤ªæ–°ï¼Œä¸ç¨³å®šï¼Œä¹Ÿä¸å…¼å®¹ä½ é¡¹ç›®é‡Œå¯èƒ½ç”¨åˆ°çš„å…¶ä»–åº“ã€‚

---

### âœ… **ç¬¬ä¸‰æ­¥ï¼šå®‰è£… stable-baselines3 ä¸ extra ä¾èµ–**

âœ” è¿™ä¸ªå‘½ä»¤ *è‡ªåŠ¨åŒ¹é…* æ‰€æœ‰ä¾èµ–æœ€ä½³ç‰ˆæœ¬
âœ” é¿å… numpy 2.x
âœ” é¿å…å´©æºƒ

```bash
pip install "stable-baselines3[extra]"
```

---

### â­ **æ­¤æ—¶ä¼šè‡ªåŠ¨å®‰è£…ï¼š**

* numpy **1.26.x**
* gymnasium 1.2
* pandas
* matplotlib
* opencv-python
* tensorboard 2.15.x
* cloudpickleã€protobuf ç­‰å…¼å®¹ç‰ˆæœ¬

ä¸ä¼šå‡ºç° numpy / cv2 å´©æºƒé—®é¢˜ã€‚

---

### âœ… **ç¬¬å››æ­¥ï¼šå®‰è£…ä½ çš„é¡¹ç›®éœ€è¦çš„å°‘é‡åº“ï¼ˆæ¥è‡ªä½ çš„ requirementsï¼‰**

ä»ä½ å‘çš„ requirements.txt ä¸­
**åªæœ‰è¿™äº›åº“åº”è¯¥ä¿ç•™å¹¶å®‰è£…ï¼š**

```bash
pip install requests jinja2 networkx
```

åŸå› ï¼š

* `requests` å¿…é¡»ï¼ˆä½ å¡”é˜²ç¯å¢ƒä¼šè®¿é—® [http://localhost:3000ï¼‰](http://localhost:3000ï¼‰)
* `jinja2` å¦‚æœä½ é¡¹ç›®ç”¨å°±è£…ï¼Œä¸ç”¨å°±ç®—äº†
* `networkx` Stable Baselines3 Extra ç”¨çš„

---

# ğŸš« **ä¸è¦å®‰è£…ä»¥ä¸‹è¿™äº›ï¼ˆä¼šç ´åç¯å¢ƒï¼‰**

* numpy==2.3.3 âŒ
* fsspec==2025.9.0 âŒ
* protobuf==6.32.1 âŒ
* torch==2.8.0 âŒ
* pandas==2.3.2ï¼ˆSB3 ä¼šè‡ªåŠ¨è£…æ›´å…¼å®¹çš„ï¼‰
* matplotlib==3.10.xï¼ˆSB3 ä¼šè‡ªåŠ¨è£…æ›´ç¨³å®šçš„ï¼‰

ä½ çš„ requirements.txt æ˜¯**åçš„åŸç¯å¢ƒ dump**ï¼Œ
ä¸èƒ½ç›´æ¥é‡è£…ã€‚

---

### ğŸŒŸ æœ€ç»ˆå¥åº·çš„ RL ç¯å¢ƒï¼ˆæˆ‘å¸®ä½ åˆ—å‡ºæœ€ç»ˆç‰ˆæœ¬ï¼‰

ä½ æˆåŠŸå®‰è£…å `pip list` ä¼šç±»ä¼¼ï¼š

```
torch 2.3.1
numpy 1.26.x
gymnasium 1.2.0
stable_baselines3 2.7.0
opencv-python 4.10.x
pandas 2.1.x
protobuf 4.x
tensorboard 2.15.x
```

è¿™ä¸€å¥—éå¸¸ç¨³å®šï¼Œä¸ä¼šå´©ã€‚

---

### ğŸ“Œ ç„¶åå¯åŠ¨å¡”é˜²APIæœåŠ¡
---
---
# å®˜æ–¹å®‰è£…æ­¥éª¤

1. Clone this repository:
    ```bash
    git clone https://github.com/Jacky8703/TowerDefenseRL.git
    cd TowerDefenseRL
    ```
2. Install dependencies:
    ```bash
    pip install -r requirements.txt
    ```
3. Clone and set up the [Tower Defense Game](https://github.com/Jacky8703/TowerDefenseGame) server as described in its README.

## Usage

The tower defense game server must be running before executing any scripts.

### Train an agent
1. Set ```hours_to_train``` in ```train.py```

2. Execute script (default map):
    ```bash 
    python train.py
    ```
    ### å¯èƒ½éœ€è¦æ³¨é‡Šæ‰env = xxx.warp()å“ªä¸€è¡Œ
    Or with random maps:
    ```bash
    python train.py --random-maps custom-maps.json
    ```
3. Monitor training progress via TensorBoard (or at the end of training):
    ```bash
    tensorboard --logdir ./logs/
    ```
4. The trained model will be saved in the `models/` directory.

In addition to the final model, a json file with the best agent performance (max waves reached) and a csv file with basic training metrics (reward, episode length and training time) will be saved.

In the `models/checkpoints/` directory, you will find periodic checkpoints of the model during training.

In the `models/videos/` directory, you will find videos of the agent's gameplay recorded at intervals during training.

In the `logs/` directory, a log file containing training metrics (visible via TensorBoard) will be created.

### Load a pre-trained model
1. If you want to continue the old training logs, add the `tb_log_name` argument to the `model.learn()` function in `train.py` with the corresponding tensorboard log name, e.g.:
    ```python
    model.learn(total_timesteps=training_steps, ..., tb_log_name="PPO_1")
    ```
2. Execute script specifying the model path:
    ```bash
    python train.py --load-model ./path/to/maskable_ppo_tower_defense.zip
    ```

### Replay best agent game (works only for the default map for now)
1. Execute the replay script specifying the json file with the best agent actions:
    ```bash
    python replay_actions.py --actions-file ./models/date_time/best_episode_actions.json
    ```
    Optionally, you can save the frames to a `best_frames` directory next to the actions file by adding the `--save-frames` argument (for future loading purposes).

2. If you have already saved the frames, you can load them directly by using the `--load-frames` argument with the path to the `best_frames` directory (much faster):
    ```bash
    python replay_actions.py --load-dir ./models/date_time/best_frames
    ```


# Infra
## Observation
- Observation oï¼ˆä»£ç†å®é™…å¯è§ï¼‰
  - ç±»å‹ä¸èŒƒå›´ï¼šspaces.Box(low=0.0, high=1.0, shape=(N,), dtype=float32)ï¼Œè§ TowerDefenseRL/gymnasium_env/envs/
    tower_defense_world.py:42ã€‚
  - ç»„æˆï¼ˆæ¯ä¸ªåˆ†é‡éƒ½å½’ä¸€åŒ–åˆ° [0,1]ï¼‰ï¼š
      - å…¨å±€ç‰¹å¾ï¼ˆ5 + 2Ã—|path cells|ï¼‰ï¼Œè§ 142 ä¸ 148ï¼š
          - [0] æ¸¸æˆæ—¶é—´ / ä¸Šé™ã€[1] æ³¢æ•° / ä¸Šé™ã€[2] é‡‘é’± / ä¸Šé™ã€[3] ç”Ÿå‘½ / ä¸Šé™ã€[4] gameOver(0/1)
          - [5:] è·¯å¾„ä¸Šæ¯ä¸ªæ ¼å­çš„å½’ä¸€åŒ–åæ ‡ x,y ä¸²æ¥
      - å¡”æ§½ä½ç‰¹å¾ï¼ˆå›ºå®šæ§½ä½ï¼Œæœ€å¤§å¡”æ•° Ã— æ¯å¡” ï¼ˆ5+|å¡”ç±»å‹|ï¼‰ï¼‰ï¼Œè§ 151â€“159ï¼š
          - æ¯å¡”ï¼šactive(1/0), x, y, æ”»é€Ÿå†·å´/æœ€æ…¢å¡”å†·å´, dps/å…¨å¡”æœ€å¤§ dps, ä»¥åŠå¡”ç±»å‹ one-hot
      - æ•Œäººæ§½ä½ç‰¹å¾ï¼ˆå›ºå®šæ§½ä½ï¼Œæœ€å¤§æ•Œäººæ•° Ã— æ¯æ•Œ ï¼ˆ5+|æ•Œç±»å‹|ï¼‰ï¼‰ï¼Œè§ 161â€“169ï¼š
          - æ¯æ•Œï¼šactive(1/0), x, y, å½“å‰è¡€é‡/æ»¡è¡€, pathProgress(0..1), æ•Œç±»å‹ one-hot
  - ç»´åº¦å¦‚ä½•ç¡®å®šï¼ˆé»˜è®¤åœ°å›¾ï¼Œä»£ç å–è‡ª GameConfigï¼‰ï¼š
      - åœ°å›¾å®½é«˜ 900Ã—600ï¼Œç½‘æ ¼ 50px â†’ 18Ã—12 å…± 216 æ ¼ï¼ˆTowerDefenseGame/src/core/GameConfig.ts:54ï¼‰ã€‚
      - è·¯å¾„åƒç´ é•¿çº¦ 2500 â†’ è·¯å¾„æ ¼æ•° â‰ˆ 2500/50 = 50ã€‚
      - å…¨å±€ç‰¹å¾ç»´æ•°ï¼š5 + 2Ã—50 = 105ã€‚
      - æœ€å¤§å¡”æ•°ï¼š216 - 50 = 166ï¼›å¡”ç±»å‹æ•°=3 â†’ æ¯å¡” 8 ç»´ â†’ 166Ã—8=1328ã€‚
      - æœ€å¤šåŒæ—¶åœ¨åœºæ•Œäººæ•°ï¼ˆä¿å®ˆä¸Šç•Œï¼‰ï¼šä¾æ®æ³¢è®¾ç½®è®¡ç®—çº¦ 33 ä¸ªï¼ˆTowerDefenseRL/gymnasium_env/envs/
        tower_defense_world.py:212â€“221ï¼‰ã€‚æ•Œç±»å‹æ•°=3 â†’ æ¯æ•Œ 8 ç»´ â†’ 33Ã—8=264ã€‚
      - æ€»è§‚æµ‹ç»´æ•° N â‰ˆ 105 + 1328 + 264 = 1697ã€‚
  - æ³¨æ„ï¼šè¿™æ˜¯ä¸€æ¡â€œå›ºå®šé•¿åº¦çš„æ‹¼æ¥å‘é‡â€ï¼Œå‰è‹¥å¹²ç»´æ˜¯å…¨å±€ä¸è·¯å¾„å¸¸é‡ï¼Œä¸­é—´ä¸€æ®µæ˜¯å¡”æ§½ä½ï¼Œå°¾éƒ¨æ˜¯æ•Œäººæ§½ä½ï¼Œæœªå ç”¨æ§½ä½å…¨ 0ã€‚

- ä¾‹å­1ï¼šåˆš reset å®Œï¼ˆè¿˜æ²¡æ”¾å¡”ï¼Œä¹Ÿæ²¡æ•Œäººï¼‰

  - å…¨å±€æ®µï¼ˆç´¢å¼• 0..4ï¼‰
      - [0] gameTime/1300 = 0.0
      - [1] waveNumber/50 = 0.0
      - [2] money/999 â‰ˆ 40/999 â‰ˆ 0.040
      - [3] lives/3 = 1.0
      - [4] gameOver = 0.0
  - è·¯å¾„åæ ‡æ®µï¼ˆç´¢å¼• 5..104ï¼Œå…± 100 ä¸ªæ•°ï¼‰
      - è¿™æ˜¯è·¯å¾„æ¯ä¸ªæ ¼ä¸­å¿ƒçš„åæ ‡æŒ‰ (x/900, y/600) ä¾æ¬¡ä¸²èµ·æ¥çš„å¸¸é‡ã€‚ä¾‹å¦‚ï¼Œå‡å¦‚å‰ä¸¤ä¸ªè·¯å¾„æ ¼ä¸­å¿ƒå¤§æ¦‚æ˜¯ (75,25)ã€(75,75)ï¼Œ
        åˆ™ï¼š
          - [5]=75/900â‰ˆ0.083ï¼Œ[6]=25/600â‰ˆ0.042
          - [7]=75/900â‰ˆ0.083ï¼Œ[8]=75/600=0.125
      - ç›´åˆ°æŠŠçº¦ 50 ä¸ªæ ¼å­çš„ (x/900,y/600) éƒ½æ”¾å®Œï¼Œå…± 100 ä¸ªå€¼ã€‚
  - å¡”æ§½ä½æ®µï¼ˆç´¢å¼• 105..1432ï¼Œå…± 166 ä¸ªæ§½ Ã— 8 ç»´ï¼‰
      - å› ä¸ºè¿˜æ²¡å¡”ï¼Œå…¨éƒ¨ä¸º 0ã€‚
  - æ•Œæ§½ä½æ®µï¼ˆç´¢å¼• 1433..1696ï¼Œå…± 33 ä¸ªæ§½ Ã— 8 ç»´ï¼‰
      - å› ä¸ºè¿˜æ²¡æ•Œï¼Œä¹Ÿå…¨éƒ¨ä¸º 0ã€‚
```bash
â€º     # encodes the self game state into a tensor of shape self.observation_space.shape
      def __get_observation(self) -> np.ndarray:
          shape = self.observation_space.shape
          if shape is None:
              raise ValueError("Observation space shape is not defined")
          observation = np.zeros(shape, dtype=np.float32)

          # global features normalized
          observation[2] = self.game_state["money"] / self.game_info["max_global_info"]["money"]
          observation[3] = self.game_state["lives"] / self.game_info["max_global_info"]["lives"]
          observation[4] = self.game_state["gameOver"]
          observation[5:5+len(self.path_cells_coordinates_normalized)] = self.path_cells_coordinates_normalized
          #observation[4:4+self.map_horizontal_cells*self.map_vertical_cells] = self.__calculate_grid_map()

          # tower features normalized
          for idx, tower in enumerate(self.game_state["towers"]):
  #æ³¨æ„self.global_feature_count = 5+len(self.path_cells_coordinates_normalized) # game time, wave number, money, lives,
  game over, path cells coordinates
              offset = self.global_feature_count + idx * self.features_per_tower
              observation[offset] = 1 # active
              observation[offset+1] = tower["position"]["x"] / self.game_info["map"]["width"] # normalized x
              observation[offset+2] = tower["position"]["y"] / self.game_info["map"]["height"] # normalized y
              observation[offset+3] = tower["attackCooldown"] / self.game_info["slower_tower_sample"]["attackCooldown"]
  # normalized attack cooldown
              observation[offset+4] = self.tower_types[self.tower_type_to_index[tower["type"]]]["dps"] /
  self.max_tower_dps # normalized dps
              observation[offset+5+self.tower_type_to_index[tower["type"]]] = 1 # one-hot encoding type

          # enemy features normalized
          for idx, enemy in enumerate(self.game_state["enemies"]):
              #æ³¨æ„self.tower_feature_count = self.max_towers * self.features_per_tower
              offset = self.global_feature_count + self.tower_feature_count + idx * self.features_per_enemy
              observation[offset] = 1 # active
              observation[offset+1] = enemy["position"]["x"] / self.game_info["map"]["width"] # normalized x
              observation[offset+2] = enemy["position"]["y"] / self.game_info["map"]["height"] # normalized y
              observation[offset+3] = enemy["currentHealth"] / enemy["fullHealth"] # normalized health
              observation[offset+4] = enemy["pathProgress"]
              observation[offset+5+self.enemy_type_to_index[enemy["type"]]] = 1 # one-hot encoding type

          return observation
```
### æ³¨æ„è¿™é‡Œç”¨åˆ°çš„global_feature_countå’Œtower_feature_countéƒ½æ˜¯åœ°å›¾è®¾å®šä¹‹åˆå°±è®¾å®šå¥½äº†çš„ã€‚
- è¿™äº› offset ä¸ç»´åº¦ï¼ˆglobal_feature_countã€tower_feature_countã€enemy_feature_countï¼‰ç¡®å®æ˜¯â€œç”±åœ°å›¾å‡ ä½•å†³å®šâ€çš„ï¼›
- ä½†å®ƒä»¬åªåœ¨ç¯å¢ƒæ„é€ æ—¶ï¼ˆinit é‡Œç¬¬ä¸€æ¬¡ GET /infoï¼‰æ ¹æ®â€œå½“æ—¶çš„åœ°å›¾â€è®¡ç®—ä¸€æ¬¡å¹¶å›ºå®šä¸‹æ¥ã€‚ä¹‹åå¦‚æœç”¨ RandomMapWrapper åœ¨
    reset å‰æ¢å›¾ï¼Œç¯å¢ƒå¹¶ä¸ä¼šé‡æ–°è®¡ç®—è¿™äº›é‡ã€‚é™¤éä½ é‡å»ºä¸€ä¸ªæ–°çš„ env å®
  ä¾‹ï¼Œå¦åˆ™å®ƒä¸ä¼šéšæ¯å¼ éšæœºåœ°å›¾é‡æ–°å®š shape æˆ–é‡ç®—è¿™äº›åç§»ã€‚
          
    observationæ˜¯graph-specificçš„ï¼Œåœ¨è¿›å…¥æ¯å¼ å›¾åˆå§‹åŒ–çš„æ—¶å€™å°±customizeäº†ä¸€ä¸ªobservation

## Action
### Action aï¼ˆä»£ç†è¾“å‡ºï¼‰

  - ç©ºé—´ï¼šspaces.MultiDiscrete([A, T, X, Y])ï¼Œè§ TowerDefenseRL/gymnasium_env/envs/tower_defense_world.py:29ã€‚
      - A=åŠ¨ä½œç±»å‹æ•°ï¼›T=å¡”ç±»å‹æ•°ï¼›X/Y=æ¨ªçºµåæ ‡æ ¼æ•°ã€‚
      - é»˜è®¤é…ç½®ä¸‹ï¼šA=2ï¼ˆNONEã€BUILD_TOWERï¼Œè§ TowerDefenseGame/src/api.ts:208ï¼‰ã€T=3ï¼ˆarcher/cannon/sniperï¼Œ
        GameConfig.ts:118ï¼‰ã€X=18ã€Y=12ã€‚
  - è¯­ä¹‰ï¼ˆstep æ—¶å¦‚ä½•è½åœ°ï¼‰ï¼Œè§ TowerDefenseRL/gymnasium_env/envs/tower_defense_world.py:70â€“76ï¼š
      - å¦‚æœé€‰çš„æ˜¯ BUILD_TOWERï¼Œä¼šæŠŠå¡”ç±»å‹ä¸æ ¼ç‚¹è½¬æ¢ä¸ºåƒç´ ä¸­å¿ƒåæ ‡å¹¶æäº¤ç»™æœåŠ¡ç«¯ã€‚
      - å¦‚æœé€‰ NONEï¼Œåæ ‡ä¸å¡”å‹åˆ†é‡è¢«å¿½ç•¥ï¼ˆä»å ä½äºåŠ¨ä½œå‘é‡ä¸­ï¼‰ã€‚
  - åŠ¨ä½œæ©ç ï¼ˆéæ³•åŠ¨ä½œå±è”½ï¼‰ï¼Œè§ 120â€“133ï¼š
      - é’±ä¸å¤Ÿæ—¶ç¦ç”¨ BUILD_TOWERï¼ˆA ç»´çš„å¯¹åº”ç±»ç›®ï¼‰ï¼›
      - å¯¹äºå•ä¸ªå¡”ç±»å‹ï¼Œè‹¥é’±ä¸å¤Ÿæˆ–æœªè§£é”åˆ™å±è”½è¯¥å¡”å‹ï¼ˆT ç»´çš„ç±»ç›®ï¼‰ï¼›
      - X/Y ç»´ä¸å±è”½ï¼ˆMultiDiscrete æ— æ³•è¡¨è¾¾â€œç‰¹å®šæ ¼å­éæ³•â€çš„äº¤å‰çº¦æŸï¼‰ï¼Œåæ ‡éæ³•ç”±ç¯å¢ƒè¿”å› -1 å°æƒ©ç½šå¤„ç†ã€‚
      - âˆ’ æŒå¸è¿‡å¤šï¼ˆè¶…è¿‡æœ€è´µå¡”ä»·ï¼‰ï¼šçº¿æ€§ç½šï¼ˆé¼“åŠ±æŠŠé’±è½¬æ¢ä¸ºæˆ˜åŠ›ï¼‰
      - âˆ’ æ‰å‘½ï¼šæ¯ç‚¹ç”Ÿå‘½ -20
      - âˆ’ æ¸¸æˆç»“æŸï¼š-100
      - é¢å¤–ï¼šè‹¥æ­¥è¿›è¯·æ±‚å› éæ³•åŠ¨ä½œè¢«æœåŠ¡å™¨æ‹’ç»ï¼ˆå¦‚æ”¾åœ¨è·¯å¾„ä¸Š/å ç”¨æ ¼ï¼‰ï¼Œæœ¬æ­¥ç›´æ¥è®° -1ï¼Œå¹¶è¿”å›â€œæœªæ›´æ–°â€çš„è§‚æµ‹ï¼Œè§ 81â€“86ã€‚

## çŠ¶æ€ s ä¸è§‚æµ‹ o çš„å…³ç³»

  - s æ˜¯æœåŠ¡ç«¯æ¸¸æˆå¼•æ“çš„çœŸå®çŠ¶æ€ï¼ˆæ—¶é—´ã€æ³¢æ•°ã€é‡‘é’±ã€ç”Ÿå‘½ã€å¡”åˆ—è¡¨ã€æ•Œäººåˆ—è¡¨ã€è·¯å¾„è¿›åº¦ç­‰ï¼Œè§ TowerDefenseGame/src/
    api.ts:101 ä¸ GameEngine ç›¸å…³æ¨¡å—ï¼‰ã€‚
  - o æ˜¯æŒ‰ä¸Šè¿°è§„åˆ™æŠŠ s å½’ä¸€åŒ–/é“ºå¹³æˆå›ºå®šé•¿åº¦å‘é‡åçš„ç»“æœï¼Œä¾›ç­–ç•¥ç½‘ç»œç›´æ¥è¾“å…¥ï¼›agent ä¸è¯»åŸå§‹å›¾åƒã€‚
  ## Episode ä¸ done å®šä¹‰

  - ç»ˆæ­¢ terminated æ¡ä»¶ï¼ˆä»»ä¸€ä¸ºçœŸï¼‰ï¼Œè§ 69â€“87 ä¸ 87 ä¹‹åé€»è¾‘ï¼š
      - gameOver=trueï¼Œæˆ–è¾¾ä¸Šé™ï¼šæ³¢æ•°â‰¥50ã€é‡‘é’±â‰¥999ï¼ˆè¿™äº›ä¸Šé™ç”± /info æä¾›ï¼ŒTowerDefenseGame/src/api.ts:200ï¼‰
  - æˆªæ–­ truncated æ¡ä»¶ï¼šæ¸¸æˆæ—¶é—´â‰¥1300ï¼ˆåŒæ ·æ¥è‡ª /infoï¼ŒTowerDefenseGame/src/api.ts:200ï¼‰
  - reset è¿”å›åˆå§‹è§‚æµ‹ä¸ infoï¼Œè§ 55â€“67ã€‚

## è®­ç»ƒæ—¶ agent å®é™…â€œè¯»åˆ°çš„æ•°æ®â€

  - æ¯ä¸€æ­¥ï¼šo_tï¼ˆçº¦ 1697 ç»´ float32 å‘é‡ï¼‰ã€å¯é€‰åŠ¨ä½œæ©ç  m_tï¼ˆé•¿åº¦ A+T+X+Y çš„å¸ƒå°”ä¸²ï¼‰ã€æ ¹æ®ç­–ç•¥é‡‡æ ·çš„ a_tï¼ˆ4 ç»´
    MultiDiscreteï¼‰ã€ç¯å¢ƒåé¦ˆ r_tã€ä¸‹ä¸€ä¸ª o_{t+1}ï¼Œä»¥åŠ done æ ‡å¿—ã€‚
  - info åªç”¨äºæ—¥å¿—/å›è°ƒï¼ˆæ³¢æ•°ã€å„å¡”æ•°é‡ã€æœ¬å›åˆåŠ¨ä½œåºåˆ—ç­‰ï¼‰ï¼Œä¸è¿›å…¥ç­–ç•¥æ›´æ–°ï¼Œè§ 173â€“184 ä¸è‡ªå®šä¹‰å›è°ƒ TowerDefenseRL/
    custom_callbacks/*ã€‚
  - æ¸²æŸ“å¸§ä»…ç”¨äºå¯è§†åŒ–/å½•åƒï¼Œä¸å‚ä¸è®­ç»ƒè¾“å…¥ï¼Œè§ render å®šä¹‰ 69 ä¹‹åä¸ TowerDefenseRL/gymnasium_env/envs/
    tower_defense_world.py:69â€“87ã€‚

## Reward
  - å¥–åŠ± r_t çš„åˆ†è§£ï¼ˆå¯¹åº”ç¯å¢ƒé‡Œçš„å¥–åŠ±å‡½æ•°ï¼Œè§ TowerDefenseRL/gymnasium_env/envs/tower_defense_world.py:223ï¼‰
      - +1 å‡»æ€å¥–åŠ±ï¼šè¿™æ­¥æ•Œäººæ•°é‡ä» 2 å˜ 1ï¼Œå¤šäº†1ä¸ªå‡»æ€ â†’ +1
      - +6 è¿‡æ³¢å¥–åŠ±ï¼šæ³¢æ•°ä» 2 å‡åˆ° 3ï¼Œè§„åˆ™æ˜¯â€œæ–°æ³¢æ•°Ã—2â€ â†’ 3Ã—2=+6
      - 0 å»ºå¡”å¥–åŠ±ï¼šè¿™æ­¥æ²¡æ–°å»ºå¡” â†’ 0
      - âˆ’2 å›¤é’±æƒ©ç½šï¼šé’±=52ï¼Œæœ€è´µå¡”=50ï¼Œè¶…è¿‡éƒ¨åˆ†ç½š (52-50)=âˆ’2
      - âˆ’20 æ‰å‘½æƒ©ç½šï¼šæ‰äº† 1 æ¡å‘½ â†’ âˆ’20
      - 0 ç»“æŸæƒ©ç½šï¼šæ²¡ç»“æŸ â†’ 0
      - åˆè®¡ï¼š1 + 6 âˆ’ 2 âˆ’ 20 = âˆ’15
  - è§‚æµ‹ o_{t+1} çš„å…³é”®å˜åŒ–ï¼ˆå¯¹åº”è§‚æµ‹ç¼–ç å‡½æ•°ï¼Œè§ TowerDefenseRL/gymnasium_env/envs/tower_defense_world.py:136ï¼‰
      - [1] æ³¢æ•°å½’ä¸€åŒ–ï¼šä» 2/50 å˜ 3/50=0.06ï¼ˆæ³¢æ•°ä¸Šå‡ï¼‰
      - [3] ç”Ÿå‘½å½’ä¸€åŒ–ï¼šä» 2/3â‰ˆ0.667 å˜ 1/3â‰ˆ0.333ï¼ˆå°‘äº†ä¸€æ¡å‘½ï¼‰
      - æ•Œäººæ§½ä½ï¼šè¿™æ­¥åâ€œå­˜æ´»çš„æ•Œäººæ•°é‡â€ä» 2 å˜ 1
          - ç¯å¢ƒä¼šæŒ‰å½“å‰æ•Œäººåˆ—è¡¨ï¼Œé‡å¤´æŠŠâ€œç¬¬ 0 æ§½ã€1 æ§½ã€â€¦â€ä¾æ¬¡å¡«ä¸Š active=1 çš„æ•Œäººç‰¹å¾ï¼Œå…¶ä½™æ§½æ¸…é›¶
          - æ‰€ä»¥ä½ çœ‹åˆ°çš„æ˜¯â€œå‰é¢è‹¥å¹²æ§½ active=1ï¼Œåé¢çš„æ§½ active=0â€ï¼›ä» 2â†’1 çš„å˜åŒ–å°±æ˜¯æœ‰ä¸€ä¸ªæ§½ä»ä¸€æ•´æ®µéé›¶å˜æˆå…¨ 0

# DQN
â€º èƒ½è°ƒåŒ…å—ï¼Ÿè‡ªå·±å®ç°å›°éš¾å—ï¼Ÿ


â€¢ ç»“è®º

  - ç›´æ¥â€œè°ƒåŒ…ç”¨ DQNâ€å¯ä»¥ï¼Œä½†è¦å…ˆæŠŠåŠ¨ä½œç©ºé—´ä» MultiDiscrete([2,3,18,12]) æ‰å¹³æˆ Discrete(1296)ã€‚SB3 çš„ DQNä¸æ”¯æŒ
    MultiDiscreteã€‚
  - è‡ªå·±å®ç° DQN éš¾åº¦ä¸é«˜ï¼Œä½†è¦åšçš„å·¥ç¨‹æ¯”ç›´æ¥ç”¨ SB3 å¤§å¾ˆå¤šï¼›è€Œä¸”æœ¬é¡¹ç›®çš„åŠ¨ä½œå·¨å¤§ä¸”å¸¦æ©ç ï¼Œçº¯ DQN å­¦ä¹ æ•ˆç‡ä¼šæ˜æ˜¾å¼±
    äº MaskablePPOã€‚

  èƒ½å¦â€œè°ƒåŒ…â€

  - å¯ä»¥ï¼šç”¨ Stable-Baselines3 çš„ DQNï¼ˆæˆ– sb3_contrib çš„ QRDQNï¼‰ï¼Œå‰ææ˜¯æŠŠåŠ¨ä½œæ”¹é€ ä¸º Discreteã€‚
  - ä¸èƒ½ç›´æ¥å¯¹æ¥ MultiDiscreteï¼šSB3 çš„ DQNä¸æ”¯æŒ MultiDiscrete/åŠ¨ä½œæ©ç ã€‚

  æ¨èæ¥å…¥æ–¹æ¡ˆï¼ˆæœ€å°æ”¹åŠ¨ï¼‰

  - ç”¨ä¸€ä¸ª ActionWrapper æŠŠ MultiDiscrete æ‰å¹³åŒ–ï¼š
      - n_actions = 2318*12 = 1296
      - æ‰å¹³ç¼–ç ï¼šidx = a*(TXY) + t*(XY) + x(Y) + y
      - åè§£ç ï¼šä¾æ¬¡æ•´é™¤å–æ¨¡è¿˜åŸ [a,t,x,y]
  - åœ¨ train.py çš„ make_model é‡ŒåŠ ä¸€ä¸ª â€œdqnâ€ åˆ†æ”¯ï¼Œç”¨ SB3 DQN åŒ…èµ·æ¥è®­ç»ƒã€‚

  æ ·ä¾‹ä»£ç ï¼ˆå¯ç›´æ¥æ”¾è¿› repoï¼‰

  - æ‰å¹³åŠ¨ä½œåŒ…è£…å™¨ï¼ˆæ–°å»º gymnasium_env/wrappers/flatten_multidiscrete.pyï¼‰ï¼š
      - é€»è¾‘ï¼šæ–° action_space æ”¹ä¸º Discrete(n_actions)ï¼Œstep æ—¶æŠŠç¦»æ•£ id è§£ç æˆåŸ MultiDiscrete å‘é‡åå†è½¬å‘ç»™åº•å±‚ envã€‚
  - è®­ç»ƒè„šæœ¬æ”¹åŠ¨æ€è·¯ï¼ˆåœ¨ TowerDefenseRL/train.py çš„ make_model åŠ ä¸€ä¸ª elif algo == "dqn":ï¼‰
      - from stable_baselines3 import DQN
      - åŒ…è£… envï¼šenv = FlattenMultiDiscreteAction(env)
      - model = DQN("MlpPolicy", env, learning_rate=3e-4, buffer_size=100_000, batch_size=256, train_freq=4,
        target_update_interval=1_000, learning_starts=10_000, gamma=0.99, verbose=1, tensorboard_log="./logs/")
  æ³¨æ„äº‹é¡¹ä¸é£é™©

  - åŠ¨ä½œæ©ç ä¼šä¸¢å¤±ï¼šDQN æ²¡æœ‰ Maskable ç‰ˆæœ¬ã€‚éæ³•åŠ¨ä½œï¼ˆå»ºå¡”é’±ä¸å¤Ÿ/æœªè§£é”/å ç”¨/åœ¨è·¯å¾„ä¸Šï¼‰ä¼šè¢«ç¯å¢ƒä»¥ -1 è½»ç½šå¤„ç†ï¼Œæ¢ç´¢æ—¶ä¼š
    ç»å¸¸æ’åˆ°ï¼Œå­¦ä¹ æ•ˆç‡æ¯” MaskablePPO å·®ã€‚
  - å¤§åŠ¨ä½œç©ºé—´ï¼šç¦»æ•£ 1296 ç»´ Q è¾“å‡ºï¼Œæ”¶æ•›æ›´æ…¢ã€‚å»ºè®®ï¼š
      - è°ƒå¤§å­¦ä¹ ç½‘ç»œï¼špolicy_kwargs=dict(net_arch=[1024, 1024])
      - åˆç†æ¢ç´¢ç­–ç•¥ï¼šexploration_fractionâ‰ˆ0.2ã€final_epsâ‰ˆ0.05

  æ¥å…¥ç»“æœ

  - æ–°å¢åŒ…è£…å™¨ï¼šgymnasium_env/wrappers/flatten_multidiscrete.py å°† MultiDiscrete([A,T,X,Y]) æ‰å¹³æˆ Discrete(A*T*X*Y)ï¼Œä¾›
    SB3 DQN ä½¿ç”¨ã€‚
  - æ‰©å±•è®­ç»ƒè„šæœ¬ï¼šTowerDefenseRL/train.py:1 æ”¯æŒ --algo dqn_sb3ï¼ˆåˆ«å dqnï¼‰ã€‚å†…éƒ¨è‡ªåŠ¨åŒ…ä¸Šæ‰å¹³åŒ…è£…å™¨ï¼Œå†æ„å»º SB3 DQNã€‚
  - è¶…å‚é»˜è®¤ï¼ˆå¯è°ƒï¼‰ï¼šbuffer_size=100k, batch_size=256, train_freq=4, target_update_interval=2500, learning_starts=10k,
    gamma=0.99, exploration_fraction=0.2, exploration_final_eps=0.05, net_arch=[1024,1024], lr=3e-4ã€‚

  å¦‚ä½•è¿è¡Œ

  - PPOï¼ˆåŸæ ·ï¼‰ï¼š
      - python train.py --algo ppo
  - DQNï¼ˆSB3 ç‰ˆï¼‰ï¼š
      - python train.py --algo dqn_sb3
      - ä¹Ÿå¯ç”¨åˆ«åï¼špython train.py --algo dqn
  - å…¶ä½™å‚æ•°æ²¿ç”¨ç°æœ‰è„šæœ¬ï¼šå¯åŠ  --random-maps custom-maps.jsonï¼ˆæ³¨æ„ä¸‹æ–¹â€œåœ°å›¾ä¸€è‡´æ€§â€ï¼‰ã€æˆ– --load-model ç»­è®­ã€‚

  æ–‡ä»¶ä¸æ”¹åŠ¨

  - æ–°å¢: TowerDefenseRL/gymnasium_env/wrappers/flatten_multidiscrete.py
      - å°† [a,t,x,y] ç¼–ç ä¸ºå•ä¸€ action_id âˆˆ [0, 1296) å¹¶åœ¨ step() ä¸­è§£ç å›å»ã€‚
  - ä¿®æ”¹: TowerDefenseRL/train.py:1
      - æ–°å¢ from stable_baselines3 import DQN ä¸ from gymnasium_env.wrappers.flatten_multidiscrete import
        FlattenMultiDiscreteAction
      - åœ¨ make_model() ä¸­åŠ å…¥ elif algo in ("dqn", "dqn_sb3"): åˆ†æ”¯ï¼Œè‡ªåŠ¨åŒ…è£¹æ‰å¹³åŒ–åŠ¨ä½œå¹¶åˆ›å»º/åŠ è½½ DQNã€‚
      - CLI å¸®åŠ©æ–‡æ¡ˆåŒ…å« ppo | dqn_sb3ã€‚

  æ³¨æ„äº‹é¡¹ï¼ˆå¼ºçƒˆå»ºè®®å…ˆæŒ‰æ­¤æ¥ï¼‰

  - åœ°å›¾ä¸€è‡´æ€§ï¼šç°ç¯å¢ƒçš„è§‚æµ‹ shape åœ¨æ„é€ æ—¶ç”±â€œåˆå§‹åœ°å›¾â€ç¡®å®šã€‚è‹¥ç”¨éšæœºåœ°å›¾è®­ç»ƒï¼Œè¯·ç¡®ä¿æ‰€æœ‰åœ°å›¾çš„ path_cells æ•°é‡ä¸€è‡´ï¼Œå¦
    åˆ™å»ºè®®å…ˆä¸è¦å¯ç”¨éšæœºåœ°å›¾ï¼Œæˆ–ç­‰æˆ‘ä»¬æ”¹ä¸ºå›ºå®šç»´çš„â€œç½‘æ ¼å›¾ç‰¹å¾â€ã€‚PPO/DQN éƒ½å—æ­¤çº¦æŸã€‚
  - åŠ¨ä½œæ©ç ï¼šDQN ä¸æ”¯æŒåŠ¨ä½œæ©ç ã€‚éæ³•åæ ‡/æœªè§£é”/é’±ä¸å¤Ÿä¼šè¢«ç¯å¢ƒä»¥ -1 è½»ç½šæ¥å…œåº•ï¼Œæ¢ç´¢é˜¶æ®µä¼šæ›´é¢‘ç¹æ’åˆ°æ— æ•ˆåŠ¨ä½œï¼Œæ”¶æ•›æ…¢äº
    MaskablePPO å±æ­£å¸¸ç°è±¡ã€‚å¯é€šè¿‡åŠ å¤§ç½‘ç»œ/å›æ”¾/è®­ç»ƒæ­¥æ•°æ¥å¼¥è¡¥ã€‚
  - å›è°ƒå…¼å®¹ï¼šCheckpoint/TensorBoard/â€œæœ€ä½³åŠ¨ä½œä¿å­˜â€åœ¨ DQN è·¯å¾„ä¸‹ä¾ç„¶å¯ç”¨ï¼›æ—¥å¿—èŠ‚å¥ä¸ PPO ç•¥æœ‰å·®å¼‚ä½†ä¸å½±å“ä½¿ç”¨ã€‚

  åç»­ï¼šhandy DQN ç«¯å£

  - ä½ å¯ä»¥æ–°å¢ --algo dqn_handy åˆ†æ”¯ï¼Œé€æ­¥å®ç°ä»¥ä¸‹æ¨¡å—å¯¹é½ SB3 DQNï¼š
      - Q ç½‘ç»œï¼ˆMLP è¾“å‡º 1296 ç»´ï¼‰ã€ç›®æ ‡ç½‘ç»œã€é‡æ”¾ç¼“å†²ã€Îµ-greedy æ¢ç´¢ã€è®­ç»ƒå¾ªç¯ï¼ˆtrain_freq/target_update é€»è¾‘ï¼‰
      - å¯¹ç…§æˆ‘è®¾çš„ SB3 è¶…å‚é€ä¸€å¤ç°ï¼Œä¿è¯ fair å¯¹æ¯”
  - æˆ‘å¯ä»¥å¸®ä½ è„šæ‰‹æ¶ dqn_handy çš„æœ€å°å¯è¿è¡Œç‰ˆæœ¬ï¼Œå†é€ä¸ªæ¨¡å—æ›¿æ¢/ä¼˜åŒ–ï¼ˆåŒé‡ DQNã€Duelingã€ä¼˜å…ˆç»éªŒå›æ”¾ç­‰ï¼‰ã€‚

  éœ€è¦æˆ‘ç°åœ¨æŠŠ --algo dqn_handy çš„ç©ºåˆ†æ”¯å…ˆåŠ å¥½å¹¶æ”¾ä¸€ä¸ªæœ€å°éª¨æ¶ï¼ˆå« ReplayBuffer/ç½‘ç»œ/è®­ç»ƒå¾ªç¯ï¼‰å—ï¼Ÿä½ å¯ä»¥è¾¹è·‘ sb3 ç‰ˆä½œä¸º
  å¯¹ç…§ï¼Œè¾¹å®Œå–„è‡ªç ”ç‰ˆã€‚